{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Use Vertex AI Vector Search to Recommend Similar Products"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0a74aaf1481"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to use the Vertex AI Vector Search Service. It is a high-scale, low-latency solution, to find similar vectors (or more specifically \"embeddings\") for a large dataset. Moreover, it is a fully managed offering, further reducing operational overhead. It is built upon [Approximate Nearest Neighbor (ANN) technology](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html) developed by Google Research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Terminology\n",
        "\n",
        "This section reviews some key terminology related to vector search.\n",
        "\n",
        "- **Vector**: A vector is a mathematical object that has both a magnitude and a direction. It is often represented as an array of numbers. In the context of machine learning, a vector is often used to represent a feature or an embedding.\n",
        "- **Embedding**: An embedding is a mathematical representation of an object, such as a word, sentence, image, or sound. In the context of machine learning, an embedding is often used to represent a feature. For this lab, product embeddings are used to represent products. Each product embedding is a 768-dimension vector meaning 768 numbers are used to represent the product.\n",
        "- **Vector Search**: Vector search is the process of finding similar vectors (or embeddings) for a given query vector. It is often used to find or recommend similar products, images, or documents.\n",
        "- **Index**: An index is a data structure that is used to store and retrieve embeddings. It is optimized for fast search and retrieval of similar embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34a4b245e795"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this notebook, you learn how to create Approximate Nearest Neighbor (ANN) Index in Vertex AI (formerly known as AI Platform), query against indexes, and validate the performance of the index. \n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "* Create an Index\n",
        "* Create an IndexEndpoint\n",
        "* Deploy an Index to an IndexEndpoint\n",
        "* Perform a vector search query\n",
        "* Compare the results with the ground truth\n",
        "\n",
        "The following diagram illustrates the different services involved:\n",
        "\n",
        "![](assets/overview.png)\n",
        "\n",
        "- The product embeddings are stored in Google Cloud Storage. The embeddings have been generated using [Vertex AI embeddings for text](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text-embeddings) using the product names\n",
        "- Each Vector Search Index is created in Vertex AI using the embeddings.\n",
        "- There are two indexes created, one using the Approximate Nearest Neighbor algorithm (ANN) and the other using the Brute Force algorithm.\n",
        "    - Nearest neighbor refers to finding the closest embedding to a given query embedding.\n",
        "    - The ANN algorithm is optimized for fast search and retrieval of similar embeddings although it is not guaranteed to find the best solution, especially for large datasets. \n",
        "    - The Brute Force algorithm will find the true nearest neighbor but is less efficient and not recommended for production. By comparing the results of the ANN and Brute Force algorithms, you can validate the performance of the ANN algorithm.\n",
        "- To query the indexes, an IndexEndpoint is created and the indexes are deployed to the endpoint.\n",
        "- IndexEndpoints can be deployed in private or public mode. In this lab, the IndexEndpoints are deployed in private mode which requires VPC peering to query the endpoints. The lab environment has been set up with VPC peering so the notebook instance can query the endpoints.\n",
        "\n",
        "*Note*: The index creation and deployment can take up to 30 minutes to complete. Because of this, they have automatically been deployed when you started this lab to save you time waiting. You will understand all of the code involved in creating and deploying the index before performing real-time queries against the index endpoints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the sample data\n",
        "\n",
        "In this lab, you will use [TheLook dataset](https://console.cloud.google.com/marketplace/product/bigquery-public-data/thelook-ecommerce) which has [products](bigquery-public-data.thelook_ecommerce.products) table with about 30,000 rows of synthetic product data for a fictitious e-commerce clothing site.\n",
        "\n",
        "![](assets/Thelook.png)\n",
        "\n",
        "From this table, a `product-embeddings.json` file has been prepared for this lab which includes 5000 product embeddings.\n",
        "\n",
        "This file is in JSONL (JSON lines) format and each row has an `id` for the product id, `name` for the product name, and `embedding` for the embedding vector of the product name in 768 dimensions which was generated using [Vertex AI Embeddings for Text](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings). A sample row from the file is as follows (where the `embedding` vector shows only 3 of the 768 dimensions):\n",
        "\n",
        "```json\n",
        "{\"id\":\"19536\",\"name\":\"original penguin men's pro-bro mock sweater\",\"embedding\":[0.015607465989887714,0.0183266568928957,0.080682516098022461,...]}\n",
        "```\n",
        "\n",
        "The text embeddings represent the meaning of the clothing product names. In this lab, you will use Vertex AI Vector Search to complete a [semantic](https://en.wikipedia.org/wiki/Semantic_search) search](https://en.wikipedia.org/wiki/Semantic_search) of the items. This sample code can be used as a basis for other simple recommendation systems where you can quickly find other items similar to a given one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0f1bea346db"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Install the following Python packages required to execute this notebook:\n",
        "\n",
        "- `google-cloud-aiplatform` - The official Python client library for Vertex AI.\n",
        "- `google-cloud-storage` - The official Python client library for Google Cloud Storage.\n",
        "- `grpcio-tools` - The gRPC tools for Python. gRPC is a high-performance, open-source universal remote procedure call (RPC) framework.\n",
        "\n",
        "You can ignore any pip errors about other dependencies as they do not impact this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfbccc635a17"
      },
      "outputs": [],
      "source": [
        "# Install the packages\n",
        "! pip3 install --upgrade google-cloud-aiplatform==1.42.1 \\\n",
        "                         google-cloud-storage \\\n",
        "                         grpcio-tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd28c9e4f067"
      },
      "source": [
        "## Before you begin\n",
        "#### Get your project ID and Number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80c0215f05a0"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = ! gcloud config get project\n",
        "PROJECT_ID = PROJECT_ID[0]\n",
        "\n",
        "# Retrieve the project number\n",
        "PROJECT_NUMBER = !gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\n",
        "PROJECT_NUMBER = PROJECT_NUMBER[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4962667eec8e"
      },
      "source": [
        "### Prepare a VPC network\n",
        "To reduce any network overhead that might lead to unnecessary increase in overhead latency, it is best to call the ANN endpoints from your VPC via a direct [VPC Peering](https://cloud.google.com/vertex-ai/docs/general/vpc-peering) connection. \n",
        "  * The following section describes how to setup a VPC Peering connection if you don't have one. \n",
        "  * This is a one-time initial setup task. You can also reuse existing VPC network and skip this section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDH8CgQiSxhv"
      },
      "outputs": [],
      "source": [
        "VPC_NETWORK = \"ai-net\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5de53b31bf1"
      },
      "source": [
        "## Make sure the following cells are run from inside the VPC network that you created in the previous step.\n",
        "\n",
        "* **WARNING:** The MatchingIndexEndpoint.match method (to create online queries against your deployed index) has to be executed in a Vertex AI Workbench notebook instance that is created with the following requirements:\n",
        "  * **In the same region as where your ANN service is deployed** (for example, if you set `REGION = \"us-central1\"` as same as the tutorial, the notebook instance has to be in `us-central1`).\n",
        "  * **Make sure you select the VPC network you created for ANN service** (instead of using the \"default\" one). That is, you will have to create the VPC network below and then create a new notebook instance that uses that VPC.  \n",
        "  * If you run it in the colab or a Vertex AI Workbench notebook instance in a different VPC network or region, \"Create Online Queries\" section will fail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "BUCKET_URI = \"{BUCKET_PLACEHOLDER}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR6Wwv-hCCN-"
      },
      "source": [
        "## Prepare the data\n",
        "\n",
        "The GloVe dataset consists of a set of pre-trained embeddings. The embeddings are split into a \"train\" split, and a \"test\" split.\n",
        "We will create a vector search index from the \"train\" split, and use the embedding vectors in the \"test\" split as query vectors to test the vector search index.\n",
        "\n",
        "**Note:** While the data split uses the term \"train\", these are pre-trained embeddings and therefore are ready to be indexed for search. The terms \"train\" and \"test\" split are used just to be consistent with machine learning terminology.\n",
        "\n",
        "Download the GloVe dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! gsutil cp \"gs://ca-lab-assets/vector-search/product-embeddings.json\" ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mglUPwHpJH98"
      },
      "source": [
        "## Create Indexes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhIBCQ7dDSbW"
      },
      "source": [
        "### Create ANN Index (for Production Usage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiIg9b5zJLi1"
      },
      "outputs": [],
      "source": [
        "DIMENSIONS = 100\n",
        "DISPLAY_NAME = \"glove_100_1\"\n",
        "DISPLAY_NAME_BRUTE_FORCE = DISPLAY_NAME + \"_brute_force\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svLYiDf0OD2G"
      },
      "source": [
        "Create the ANN index configuration:\n",
        "\n",
        "To learn more about configuring the index, see [Input data format and structure](https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup/format-structure).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4zooldkGoM4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(location=\"us-central1\", staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzY7TpUSJcTV"
      },
      "outputs": [],
      "source": [
        "tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
        "    display_name=DISPLAY_NAME,\n",
        "    contents_delta_uri=EMBEDDINGS_INITIAL_URI,\n",
        "    dimensions=DIMENSIONS,\n",
        "    approximate_neighbors_count=50,\n",
        "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
        "    leaf_node_embedding_count=50,\n",
        "    leaf_nodes_to_search_percent=7,\n",
        "    description=\"Glove 100 ANN index\",\n",
        "    labels={\"label_name\": \"label_value\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17jrQi501QyX"
      },
      "outputs": [],
      "source": [
        "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
        "INDEX_RESOURCE_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f1a9fbecabb"
      },
      "source": [
        "Using the resource name, you can retrieve an existing MatchingEngineIndex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ddb70647d98"
      },
      "outputs": [],
      "source": [
        "tree_ah_index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSsqZuyoA1SG"
      },
      "source": [
        "### Create Brute Force Index (for Ground Truth)\n",
        "\n",
        "The brute force index uses a naive brute force method to find the nearest neighbors. This method is not fast or efficient. Hence brute force indices are not recommended for production usage. They are to be used to find the \"ground truth\" set of neighbors, so that the \"ground truth\" set can be used to measure recall of the indices being tuned for production usage. To ensure an apples to apples comparison, the `distanceMeasureType` and `dimensions` of the brute force index should match those of the production indices being tuned.\n",
        "\n",
        "Create the brute force index configuration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXnBLqjXBsv8"
      },
      "outputs": [],
      "source": [
        "brute_force_index = aiplatform.MatchingEngineIndex.create_brute_force_index(\n",
        "    display_name=DISPLAY_NAME_BRUTE_FORCE,\n",
        "    contents_delta_uri=EMBEDDINGS_INITIAL_URI,\n",
        "    dimensions=DIMENSIONS,\n",
        "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
        "    description=\"Glove 100 index (brute force)\",\n",
        "    labels={\"label_name\": \"label_value\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oD5SieYJbbW"
      },
      "outputs": [],
      "source": [
        "INDEX_BRUTE_FORCE_RESOURCE_NAME = brute_force_index.resource_name\n",
        "INDEX_BRUTE_FORCE_RESOURCE_NAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "865fcad494d7"
      },
      "outputs": [],
      "source": [
        "brute_force_index = aiplatform.MatchingEngineIndex(\n",
        "    index_name=INDEX_BRUTE_FORCE_RESOURCE_NAME\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omlgEZ-sGoM5"
      },
      "source": [
        "## Update Indexes\n",
        "\n",
        "Create incremental data file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDAvm_mj_BVs"
      },
      "outputs": [],
      "source": [
        "with open(\"glove100_incremental.json\", \"w\") as f:\n",
        "    index = 0\n",
        "    f.write(\n",
        "        json.dumps(\n",
        "            {\n",
        "                \"id\": str(index),\n",
        "                \"embedding\": [str(0) for _ in train[index]],\n",
        "                \"restricts\": [\n",
        "                    {\n",
        "                        \"namespace\": \"class\",\n",
        "                        \"allow_list\": [\"even\" if index % 2 == 0 else \"odd\"],\n",
        "                    }\n",
        "                ],\n",
        "            }\n",
        "        )\n",
        "        + \"\\n\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU7TU7C7GoM6"
      },
      "source": [
        "Copy the incremental data file to a new subdirectory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLWcDvNLGoM6"
      },
      "outputs": [],
      "source": [
        "EMBEDDINGS_UPDATE_URI = f\"{BUCKET_URI}/matching-engine/incremental/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgpEDX0oGoM6"
      },
      "outputs": [],
      "source": [
        "! gsutil cp glove100_incremental.json {EMBEDDINGS_UPDATE_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiXtF_x0GoM6"
      },
      "source": [
        "Create update index request\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvedBONtGoM6"
      },
      "outputs": [],
      "source": [
        "tree_ah_index = tree_ah_index.update_embeddings(\n",
        "    contents_delta_uri=EMBEDDINGS_UPDATE_URI,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKPDojFpGoM6"
      },
      "outputs": [],
      "source": [
        "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
        "INDEX_RESOURCE_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV2xjAnDDObD"
      },
      "source": [
        "## Create an IndexEndpoint with VPC Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpZQoJyxDlbO"
      },
      "outputs": [],
      "source": [
        "VPC_NETWORK = \"ai-net\"\n",
        "VPC_NETWORK_FULL = f\"projects/{PROJECT_NUMBER}/global/networks/{VPC_NETWORK}\"\n",
        "VPC_NETWORK_FULL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuARXzJVGyQX"
      },
      "outputs": [],
      "source": [
        "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
        "    display_name=\"product_index_endpoint\",\n",
        "    description=\"product index endpoint\",\n",
        "    network=VPC_NETWORK_FULL,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ3bcZqi-cfM"
      },
      "outputs": [],
      "source": [
        "INDEX_ENDPOINT_NAME = my_index_endpoint.resource_name\n",
        "INDEX_ENDPOINT_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np2cgVuuIe9k"
      },
      "source": [
        "## Deploy Indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ew1UgcIIiJG"
      },
      "source": [
        "### Deploy ANN Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLOYTGygIlMK"
      },
      "outputs": [],
      "source": [
        "DEPLOYED_INDEX_ID = \"product_deployed_index\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uK4WOgqN1NG"
      },
      "outputs": [],
      "source": [
        "my_index_endpoint = my_index_endpoint.deploy_index(\n",
        "    index=tree_ah_index, deployed_index_id=DEPLOYED_INDEX_ID\n",
        ")\n",
        "\n",
        "my_index_endpoint.deployed_indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNZnXmO5AhDO"
      },
      "source": [
        "### Deploy Brute Force Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p9e4828AkSv"
      },
      "outputs": [],
      "source": [
        "DEPLOYED_BRUTE_FORCE_INDEX_ID = \"product_brute_force_deployed_index\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2kgd01SA4rk"
      },
      "outputs": [],
      "source": [
        "my_index_endpoint = my_index_endpoint.deploy_index(\n",
        "    index=brute_force_index, deployed_index_id=DEPLOYED_BRUTE_FORCE_INDEX_ID\n",
        ")\n",
        "\n",
        "my_index_endpoint.deployed_indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confirm Index Deployment\n",
        "\n",
        "If the indexes are still deploying, you can learn more about [Vertex AI Vector Search](https://cloud.google.com/vertex-ai/docs/matching-engine/overview) while waiting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LCGvBNvBd8D"
      },
      "source": [
        "## Create Online Queries\n",
        "\n",
        "After you built your indexes, you may query against the deployed index through the online querying gRPC API (Match service) within the virtual machine instances from the same region (for example 'us-central1' in this tutorial).\n",
        "\n",
        "The `filter` parameter is an optional way to filter for a subset of embeddings. In this case, only embeddings that have the `class` set as `even` are returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# build dictionaries for product names and embeddings\n",
        "product_names = {}\n",
        "product_embeddings = {}\n",
        "with open(\"product-embeddings.json\") as f:\n",
        "    for l in f.readlines():\n",
        "        p = json.loads(l)\n",
        "        id = p[\"id\"]\n",
        "        product_names[id] = p[\"name\"]\n",
        "        product_embeddings[id] = p[\"embedding\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the embedding for ID 17268 \"hurley juniors supersuede beachrider boardshort\"\n",
        "# you can also try with other IDs such as 18090, 19536 and 11863\n",
        "query_embedding = product_embeddings[\"12711\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "index_endpoints = aiplatform.MatchingEngineIndexEndpoint.list()\n",
        "index_endpoint = None\n",
        "for i in index_endpoints:\n",
        "    if \"brute-force\" not in i.display_name:\n",
        "        index_endpoint = i\n",
        "        break\n",
        "        \n",
        "index_endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3KYVw5HB-4v"
      },
      "outputs": [],
      "source": [
        "# Test query\n",
        "\n",
        "DEPLOYED_INDEX_ID = 'product_deployed_index'\n",
        "NUM_NEIGHBOURS = 10 # The number of nearest neighbors to be retrieved\n",
        "\n",
        "# Execute the request\n",
        "response = my_index_endpoint.find_neighbors(\n",
        "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
        "    queries=[query_embedding],\n",
        "    num_neighbors=NUM_NEIGHBOURS,\n",
        ")\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# show the results\n",
        "for idx, neighbor in enumerate(response[0]):\n",
        "    print(f\"{neighbor.distance:.2f} {product_names[neighbor.id]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeUZO3bAGoM-"
      },
      "source": [
        "### Compute Recall\n",
        "\n",
        "Use the deployed brute force Index as the ground truth to calculate the recall of ANN Index. Note that you can run multiple queries in a single match call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9dNIbkEGoM-"
      },
      "outputs": [],
      "source": [
        "# Retrieve nearest neighbors for both the tree-AH index and the brute-force index\n",
        "tree_ah_response_test = my_index_endpoint.match(\n",
        "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
        "    queries=list(test),\n",
        "    num_neighbors=NUM_NEIGHBOURS,\n",
        ")\n",
        "brute_force_response_test = my_index_endpoint.match(\n",
        "    deployed_index_id=DEPLOYED_BRUTE_FORCE_INDEX_ID,\n",
        "    queries=list(test),\n",
        "    num_neighbors=NUM_NEIGHBOURS,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-eMF05UGoM-"
      },
      "outputs": [],
      "source": [
        "# Calculate recall by determining how many neighbors were correctly retrieved as compared to the brute-force option.\n",
        "recalled_neighbors = 0\n",
        "for tree_ah_neighbors, brute_force_neighbors in zip(\n",
        "    tree_ah_response_test, brute_force_response_test\n",
        "):\n",
        "    tree_ah_neighbor_ids = [neighbor.id for neighbor in tree_ah_neighbors]\n",
        "    brute_force_neighbor_ids = [neighbor.id for neighbor in brute_force_neighbors]\n",
        "\n",
        "    recalled_neighbors += len(\n",
        "        set(tree_ah_neighbor_ids).intersection(brute_force_neighbor_ids)\n",
        "    )\n",
        "\n",
        "recall = recalled_neighbors / len(\n",
        "    [neighbor for neighbors in brute_force_response_test for neighbor in neighbors]\n",
        ")\n",
        "\n",
        "print(\"Recall: {}\".format(recall))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sdk_matching_engine_for_indexing.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
